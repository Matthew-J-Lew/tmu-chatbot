version: "3.9"

services:
  pg:
    image: pgvector/pgvector:pg16
    container_name: arts_pg
    environment:
      POSTGRES_DB: ragdb
      POSTGRES_USER: rag
      POSTGRES_PASSWORD: rag
    ports:
      - "5432:5432"
    volumes:
      # Auto-run schema on first init:
      - ./app/ingestion/schema.sql:/docker-entrypoint-initdb.d/01_schema.sql:ro
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U rag -d ragdb"]
      interval: 5s
      timeout: 3s
      retries: 20

  ollama:
    image: ollama/ollama:latest
    container_name: arts_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -s http://localhost:11434/api/tags || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 20

  api:
    build: ./app/api
    container_name: arts_api
    environment:
      PGHOST: pg
      PGUSER: rag
      PGPASSWORD: rag
      PGDATABASE: ragdb
      OLLAMA_HOST: http://ollama:11434
      LLM_MODEL: llama3.1:8b-instruct
      EMBEDDING_MODEL: sentence-transformers/all-MiniLM-L6-v2
      PYTHONUNBUFFERED: "1"
    depends_on:
      pg:
        condition: service_healthy
      ollama:
        condition: service_healthy
    ports:
      - "8000:8000"

  # Optional one-shot ingestion container.
  ingestion:
    build: ./app/ingestion
    container_name: arts_ingestion
    profiles: ["ingest"]        # only runs with: docker compose --profile ingest up ingestion
    environment:
      PGHOST: pg
      PGUSER: rag
      PGPASSWORD: rag
      PGDATABASE: ragdb
    depends_on:
      pg:
        condition: service_healthy

  # Optional static widget preview (serve /app/frontend)
  # frontend:
  #   image: nginx:alpine
  #   volumes:
  #     - ./app/frontend:/usr/share/nginx/html:ro
  #   ports:
  #     - "8080:80"
  #   depends_on:
  #     - api

volumes:
  pgdata:
  ollama:
